{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "use-speech-recognition",
  "type": "registry:hook",
  "title": "useSpeechRecognition",
  "description": "A React hook for speech-to-text conversion using the Web Speech API.",
  "categories": [
    "speech"
  ],
  "files": [
    {
      "path": "speech/use-speech-recognition.ts",
      "type": "registry:hook",
      "content": "import { useState, useEffect, useCallback, useRef } from \"react\";\n\n/**\n * Speech recognition error types\n */\nexport type SpeechRecognitionErrorCode =\n    | \"no-speech\"\n    | \"aborted\"\n    | \"audio-capture\"\n    | \"network\"\n    | \"not-allowed\"\n    | \"service-not-allowed\"\n    | \"bad-grammar\"\n    | \"language-not-supported\";\n\n/**\n * Options for the useSpeechRecognition hook\n */\nexport interface UseSpeechRecognitionOptions {\n    /** Language for recognition (BCP 47 format, e.g., 'en-US', 'es-ES') */\n    lang?: string;\n    /** Keep listening after user stops speaking (default: false) */\n    continuous?: boolean;\n    /** Return interim results before final transcription (default: true) */\n    interimResults?: boolean;\n    /** Maximum number of alternative transcriptions to return (default: 1) */\n    maxAlternatives?: number;\n    /** Callback when a final result is received */\n    onResult?: (transcript: string, isFinal: boolean) => void;\n    /** Callback when an error occurs */\n    onError?: (error: SpeechRecognitionErrorCode) => void;\n    /** Callback when recognition ends */\n    onEnd?: () => void;\n}\n\n/**\n * Return type for useSpeechRecognition hook\n */\nexport interface UseSpeechRecognitionReturn {\n    /** The final transcribed text */\n    transcript: string;\n    /** The interim (in-progress) transcribed text */\n    interimTranscript: string;\n    /** Whether speech recognition is currently active */\n    isListening: boolean;\n    /** Whether the Speech Recognition API is supported */\n    isSupported: boolean;\n    /** The error code if recognition failed */\n    error: SpeechRecognitionErrorCode | null;\n    /** Human-readable error message */\n    errorMessage: string | null;\n    /** Start listening for speech */\n    start: () => void;\n    /** Stop listening gracefully (waits for final result) */\n    stop: () => void;\n    /** Abort listening immediately (discards results) */\n    abort: () => void;\n    /** Reset the transcript to empty */\n    resetTranscript: () => void;\n}\n\n/**\n * Human-readable error messages for speech recognition errors\n */\nfunction getErrorMessage(error: SpeechRecognitionErrorCode): string {\n    switch (error) {\n        case \"no-speech\":\n            return \"No speech was detected. Please try again.\";\n        case \"aborted\":\n            return \"Speech recognition was aborted.\";\n        case \"audio-capture\":\n            return \"No microphone was found or microphone access failed.\";\n        case \"network\":\n            return \"Network error occurred during recognition.\";\n        case \"not-allowed\":\n            return \"Microphone permission denied. Please allow access in your browser settings.\";\n        case \"service-not-allowed\":\n            return \"Speech recognition service is not allowed.\";\n        case \"bad-grammar\":\n            return \"Speech grammar error occurred.\";\n        case \"language-not-supported\":\n            return \"The specified language is not supported.\";\n        default:\n            return \"An unknown error occurred during speech recognition.\";\n    }\n}\n\n// Type declarations for the Web Speech API (not fully typed in TypeScript)\ninterface SpeechRecognitionEvent extends Event {\n    resultIndex: number;\n    results: SpeechRecognitionResultList;\n}\n\ninterface SpeechRecognitionErrorEvent extends Event {\n    error: SpeechRecognitionErrorCode;\n    message: string;\n}\n\ninterface SpeechRecognitionResultList {\n    length: number;\n    item(index: number): SpeechRecognitionResult;\n    [index: number]: SpeechRecognitionResult;\n}\n\ninterface SpeechRecognitionResult {\n    length: number;\n    item(index: number): SpeechRecognitionAlternative;\n    [index: number]: SpeechRecognitionAlternative;\n    isFinal: boolean;\n}\n\ninterface SpeechRecognitionAlternative {\n    transcript: string;\n    confidence: number;\n}\n\ninterface SpeechRecognitionInstance extends EventTarget {\n    continuous: boolean;\n    interimResults: boolean;\n    lang: string;\n    maxAlternatives: number;\n    start(): void;\n    stop(): void;\n    abort(): void;\n    onresult: ((event: SpeechRecognitionEvent) => void) | null;\n    onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;\n    onend: (() => void) | null;\n    onstart: (() => void) | null;\n    onspeechend: (() => void) | null;\n}\n\ndeclare global {\n    interface Window {\n        SpeechRecognition: new () => SpeechRecognitionInstance;\n        webkitSpeechRecognition: new () => SpeechRecognitionInstance;\n    }\n}\n\n/**\n * A React hook that provides speech-to-text functionality using the\n * Web Speech Recognition API.\n *\n * @param options - Configuration options for the hook\n * @returns UseSpeechRecognitionReturn object with transcript and control functions\n *\n * @example\n * ```tsx\n * // Basic usage\n * const { transcript, isListening, start, stop } = useSpeechRecognition();\n *\n * // With options\n * const { transcript, interimTranscript } = useSpeechRecognition({\n *     lang: 'es-ES',\n *     continuous: true,\n *     interimResults: true\n * });\n * ```\n */\nexport function useSpeechRecognition(\n    options: UseSpeechRecognitionOptions = {},\n): UseSpeechRecognitionReturn {\n    const {\n        lang = \"en-US\",\n        continuous = false,\n        interimResults = true,\n        maxAlternatives = 1,\n        onResult,\n        onError,\n        onEnd,\n    } = options;\n\n    const [transcript, setTranscript] = useState(\"\");\n    const [interimTranscript, setInterimTranscript] = useState(\"\");\n    const [isListening, setIsListening] = useState(false);\n    const [error, setError] = useState<SpeechRecognitionErrorCode | null>(null);\n    const [errorMessage, setErrorMessage] = useState<string | null>(null);\n\n    // Use refs for callbacks to avoid re-creating the recognition instance\n    // when callbacks change (which happens on every render if not memoized)\n    const onResultRef = useRef(onResult);\n    const onErrorRef = useRef(onError);\n    const onEndRef = useRef(onEnd);\n\n    const recognitionRef = useRef<SpeechRecognitionInstance | null>(null);\n    const isManualStopRef = useRef(false);\n\n    useEffect(() => {\n        onResultRef.current = onResult;\n        onErrorRef.current = onError;\n        onEndRef.current = onEnd;\n    }, [onResult, onError, onEnd]);\n\n    // Check if API is supported\n    const isSupported =\n        typeof window !== \"undefined\" &&\n        (\"SpeechRecognition\" in window || \"webkitSpeechRecognition\" in window);\n\n    // Initialize recognition instance\n    useEffect(() => {\n        if (!isSupported) return;\n\n        const SpeechRecognitionAPI =\n            window.SpeechRecognition || window.webkitSpeechRecognition;\n        const recognition = new SpeechRecognitionAPI();\n\n        recognition.continuous = continuous;\n        recognition.interimResults = interimResults;\n        recognition.lang = lang;\n        recognition.maxAlternatives = maxAlternatives;\n\n        recognition.onstart = () => {\n            setIsListening(true);\n            setError(null);\n            setErrorMessage(null);\n        };\n\n        recognition.onresult = (event: SpeechRecognitionEvent) => {\n            let finalTranscript = \"\";\n            let currentInterim = \"\";\n\n            for (let i = event.resultIndex; i < event.results.length; i++) {\n                const result = event.results[i];\n                if (!result || !result[0]) continue;\n\n                if (result.isFinal) {\n                    finalTranscript += result[0].transcript;\n                } else {\n                    currentInterim += result[0].transcript;\n                }\n            }\n\n            if (finalTranscript) {\n                setTranscript((prev) => prev + finalTranscript);\n                onResultRef.current?.(finalTranscript, true);\n            }\n\n            setInterimTranscript(currentInterim);\n            if (currentInterim) {\n                onResultRef.current?.(currentInterim, false);\n            }\n        };\n\n        recognition.onerror = (event: SpeechRecognitionErrorEvent) => {\n            const errorCode = event.error;\n            setError(errorCode);\n            setErrorMessage(getErrorMessage(errorCode));\n            setIsListening(false);\n            onErrorRef.current?.(errorCode);\n        };\n\n        recognition.onend = () => {\n            setIsListening(false);\n            setInterimTranscript(\"\");\n\n            // Auto-restart if continuous mode and not manually stopped\n            if (continuous && !isManualStopRef.current && !error) {\n                try {\n                    recognition.start();\n                } catch {\n                    // Ignore if already started\n                }\n            }\n\n            onEndRef.current?.();\n        };\n\n        recognitionRef.current = recognition;\n\n        return () => {\n            recognition.abort();\n        };\n    }, [isSupported, lang, continuous, interimResults, maxAlternatives]); // Removed callbacks from dependencies\n\n    // Update recognition settings when options change\n    useEffect(() => {\n        if (recognitionRef.current) {\n            recognitionRef.current.lang = lang;\n            recognitionRef.current.continuous = continuous;\n            recognitionRef.current.interimResults = interimResults;\n            recognitionRef.current.maxAlternatives = maxAlternatives;\n        }\n    }, [lang, continuous, interimResults, maxAlternatives]);\n\n    const start = useCallback(() => {\n        if (!isSupported || !recognitionRef.current) return;\n\n        isManualStopRef.current = false;\n        setError(null);\n        setErrorMessage(null);\n\n        try {\n            recognitionRef.current.start();\n        } catch {\n            // Ignore if already started - this can happen in continuous mode\n        }\n    }, [isSupported]);\n\n    const stop = useCallback(() => {\n        if (!recognitionRef.current) return;\n\n        isManualStopRef.current = true;\n        recognitionRef.current.stop();\n    }, []);\n\n    const abort = useCallback(() => {\n        if (!recognitionRef.current) return;\n\n        isManualStopRef.current = true;\n        recognitionRef.current.abort();\n        setInterimTranscript(\"\");\n    }, []);\n\n    const resetTranscript = useCallback(() => {\n        setTranscript(\"\");\n        setInterimTranscript(\"\");\n    }, []);\n\n    return {\n        transcript,\n        interimTranscript,\n        isListening,\n        isSupported,\n        error,\n        errorMessage,\n        start,\n        stop,\n        abort,\n        resetTranscript,\n    };\n}\n\nexport default useSpeechRecognition;\n"
    }
  ]
}